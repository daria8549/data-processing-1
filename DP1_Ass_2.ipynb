{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8b4ced-9b69-4c8e-a7d0-12265cc28eea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbfb02fdc67dc903abb412ab000bf72",
     "grade": false,
     "grade_id": "cell-01518f30645ea1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2 \n",
    "\n",
    "-----\n",
    "## Step 0 (2 points)\n",
    "\n",
    "Find two data sets online (from one or several sources) that would be interesting to combine and create ***data citations*** as Python dictionaries. \n",
    "\n",
    "Store the data citation in a dictionary for each of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ac2b05-1102-4cf7-96a3-f1ec47459ece",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b6ee8b15f725340d21f67892d57f1cf",
     "grade": true,
     "grade_id": "cell-cea2669d70d8d76a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "dataset1= {\n",
    "    \"creator\" : \"European Environment Agency (EEA)\" ,\n",
    "    \"catalogName\" : \"Eurostat\" ,\n",
    "    \"catalogURL\" : \"https://ec.europa.eu/eurostat/de/home\" ,\n",
    "    \"datasetID\" : \"https://ec.europa.eu/eurostat/databrowser/view/env_air_emis__custom_13506018/default/table?lang=en\" ,\n",
    "    \"resourceURL\" : \"https://github.com/crazy-donuts/Air-pollutants/raw/main/Air%20pollutants.csv\"  ,\n",
    "    \"pubYear\" : \"2024\"  ,\n",
    "    \"lastAccessed\" : \"\"  ,\n",
    "}\n",
    "\n",
    "dataset2= {\n",
    "    \"creator\" : \"Eurostat\" ,\n",
    "    \"catalogName\" : \"Eurostat\" ,\n",
    "    \"catalogURL\" : \"https://ec.europa.eu/eurostat/de/home\" ,\n",
    "    \"datasetID\" : \"https://ec.europa.eu/eurostat/databrowser/view/road_tf_vehmov__custom_13506734/default/table?lang=en\" ,\n",
    "    \"resourceURL\" : \"https://github.com/crazy-donuts/Road-motor-vehicle-traffic-performance/raw/main/Road%20motor%20vehicle%20traffic%20performance.json\"  ,\n",
    "    \"pubYear\" : \"2024\"  ,\n",
    "    \"lastAccessed\" : \"\"  ,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852966b3-7ce6-47e0-a879-2de74b756861",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39009fd5ac6f4d6b559120b873b92451",
     "grade": true,
     "grade_id": "cell-d3cc293b6207d1c7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "\n",
    "assert_equal(type(dataset1), dict)\n",
    "assert_equal(type(dataset2), dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04cd31-a41c-4d42-b756-87567ed08ee8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25e589c21292c28ecbe9193e15daa7b9",
     "grade": true,
     "grade_id": "cell-9bc09f21e0c42050",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Dataset 1: Air Pollutants by Source for European Countries\n",
    "This dataset provides information on the trends in air pollutant levels across European countries from 1980 to 2022. No data condensation is required\n",
    "\n",
    "Dataset 2: Road motor vehicle traffic performance by traffic, registration location and type of vehicle\n",
    "This dataset captures the performance metrics (Million vehicle-kilometres) of road motor vehicle traffic. It provides information into traffic distribution and vehicle usage patterns across different regions and vehicle categories. No data condensation is required\n",
    "\n",
    "Project Idea: \n",
    "We’re looking into whether there’s a link between how much traffic there is and the levels of air pollution in Europe. While we know that pollution can come from other sources like industry, we’re assuming here that traffic is the main contributor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43ce55-9c0b-44b2-a833-8e4e107175da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4c6631a22555c4c784b89e218ae1012",
     "grade": false,
     "grade_id": "cell-426859b26b9c84e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------\n",
    "## Step 1 - File Access (3 points)\n",
    "\n",
    "Write a Python function `accessData` that takes the dataset dictionary created in step 0 as an input and returns an extended dictionary including following additions:\n",
    "\n",
    "* Write code that accesses the dataset from its `resourceURL` using the python `requests` package:\n",
    " * detects whether it's and XML, CSV or JSON file by\n",
    "     * checking whether the download URL **ends** with suffix \"xml\", \"json\", \"csv\" (in either upper- or lowercase)\n",
    "     * checking whether the \"Content-Type\" HTTP header field contains information about the format, hinting on XML, JSON or CSV, i.e., check whether the substring XML, JSON or CSV appears in the \"Content-Type\" header in either upper- or lowercase. \n",
    " * Detects the file size from the HTTP header (converted to KB) of each data set, clearly documenting your actions (e.g. through commented code).\n",
    "\n",
    "The result of the code below should extend your dictionaries `dataset1` and `dataset2` with two keys named \n",
    "* `\"detectedFormat\"` (which has one of the following values: `\"XML\"`, `\"JSON\"`, `\"CSV\"`, or `\"unknown\"`, if nothing could be detected from checking the suffix or HTTP header, or if the information in both was inconsistent)\n",
    "* and `\"filesizeKB\"` which contains the filesize in KB (Conversion should be done accordingly to decimal SI prefixes) from the number of bytes in the header-information. If there is no respective header information return 0.\n",
    "* If the detected format is `\"unknown\"`, the expected filesize to be returned is also 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a06da511-204d-4316-bc92-507835acbe27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce47a1d2b5782eb291c725baea5db29",
     "grade": false,
     "grade_id": "cell-87173edcb1445261",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \n",
    "import requests\n",
    "\n",
    "def accessData(datadict):\n",
    "    resourceURL = datadict[\"resourceURL\"]\n",
    "    #we retrieve the header info\n",
    "    r = requests.get(resourceURL)\n",
    "    rhead = r.headers \n",
    "    #lets check if the sufix indicates the file type\n",
    "    suffix = resourceURL.split('.')[-1].lower()\n",
    "    if \"xml\" in suffix:\n",
    "        datadict[\"detectedFormat\"] = \"XML\"\n",
    "    elif \"json\" in suffix:\n",
    "        datadict[\"detectedFormat\"] = \"JSON\"\n",
    "    elif \"csv\" in suffix:\n",
    "        datadict[\"detectedFormat\"] = \"CSV\"\n",
    "    else:\n",
    "        content_type = rhead.get(\"Content-Type\", \"\").lower()\n",
    "        if \"xml\" in content_type:\n",
    "            datadict[\"detectedFormat\"] = \"XML\"\n",
    "        elif \"json\" in content_type:\n",
    "            datadict[\"detectedFormat\"] = \"JSON\"\n",
    "        elif \"csv\" in content_type:\n",
    "            datadict[\"detectedFormat\"] = \"CSV\"\n",
    "        else:\n",
    "            datadict[\"detectedFormat\"] = \"unknown\"\n",
    "   \n",
    "    \n",
    "    if datadict[\"detectedFormat\"] != \"unknown\":\n",
    "        file_size = int(r.headers.get(\"Content-Length\", 0))\n",
    "        filesizeKB = int(file_size / 1024)\n",
    "        datadict[\"filesizeKB\"] = filesizeKB\n",
    "    else:\n",
    "        datadict[\"filesizeKB\"] = 0\n",
    "    return datadict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba078d8-b700-4cb8-8a18-4a2fa86dc210",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0d78a1c235cdfbf979a515129ddf98f",
     "grade": true,
     "grade_id": "cell-09b529ecf9606ac6",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Basic tests to see if your solution meets the foundational demands described in the task description\n",
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "dataset1= accessData(dataset1)\n",
    "dataset2= accessData(dataset2)\n",
    "assert_in(dataset1[\"detectedFormat\"], [\"XML\", \"JSON\", \"CSV\", \"unknown\"])\n",
    "assert_in(dataset2[\"detectedFormat\"], [\"XML\", \"JSON\", \"CSV\", \"unknown\"])\n",
    "assert_true(isinstance(dataset1[\"filesizeKB\"], (int, float)))\n",
    "assert_true(isinstance(dataset2[\"filesizeKB\"], (int, float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ffd91-c334-43fd-aa68-ae9aeb9ae24b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56e8a3407f0b2570544c4791d8468d5f",
     "grade": true,
     "grade_id": "cell-40248ad63aa2baea",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "\n",
    "Data Set 1\n",
    "Format: CSV\n",
    "Size: 47 KB\n",
    "\n",
    "\n",
    "Data Set 2\n",
    "Format: JSON\n",
    "Size: 11 KB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26a4ed-ce75-4a64-8c94-0eff3cb8de7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8ba2987efce440ec7e6f4d4857bd88e",
     "grade": false,
     "grade_id": "cell-c236c8ec72c4dded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## Step 2  (5 points) - Format Validation\n",
    "\n",
    "Establish that the two data files obtained are well-formed according to the detected data format (CSV, JSON, or XML). That is, the syntax used is valid according to accepted syntax definitions. Are there any violations of well-formedness?\n",
    "\n",
    "\n",
    "Proceed as follows (for each data file, in turn): according to the \"suspected\" data format from Step 1:\n",
    "\n",
    "  1. Use an _online validator_ for CSV, XML, and JSON, respectively, to confirm whether the files you downloaded in Step 1 are well-formed for the respective file format, document your findings and modify the file as described: \n",
    "\n",
    "   a. **Case 1**: no well-formedness errors were detected: \n",
    "    * Generally describe at least 3 well-formedness checks that your data sets, depending on its \"suspected\" format (against the background knowledge of Unit 2) should fulfill;\n",
    "    * Store a local copy of the file called `data_notebook-[notebook-nr.]_[name].[file extension]` in the `data/` subfolder\n",
    "    * Create another local copy of your data file called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]` and introduce a selected well-formedness violation (one occurrence) therein;\n",
    "    * document that the online validator you used finds the error you introduced\n",
    "\n",
    "   b. **Case 2**: well-formedness errors occurred:\n",
    "    * Document the occurrences by printing out the error message and describe the types of well-formedness violation that were reported to you.\n",
    "    * Store a local copy called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]`  in the `data/ subfolder`\n",
    "    * Create another local copy called `data_notebook-[notebook-nr.]_[name].[file extension]`, of your data file that fixes the well-formedness violations therein manually.  \n",
    "    \n",
    "**Please note that the datasets in the `data/` subfolder are for documentation only. Do not access those for subsequent steps!**\n",
    "    \n",
    "\n",
    "  2. Write a Python function `parseFile(datadict, format)` that that accesses the dataset from its `resourceURL`. The dataset should then be checked accordingly the given parser for the parameter `format` to check the following:\n",
    "     * CSV: Returns `True`, if a consistent delimiter out of `\",\",\";\",\"\\t\"` can be detected, such that each row has the same (> 1) number of elements, otherwise False\n",
    "     * JSON: Returns `True` if the file can be parsed with the `json` package, catching any parsing exceptions.\n",
    "     * XML: Returns `True` if the file can be parsed with the `xmltodict` package, catching any parsing exceptions.\n",
    "     * Returns `False` if any other format is supplied by the parameter.\n",
    "     \n",
    "In order to handle parsing exceptions and errors from the used packages, you can use [catching exceptions](https://docs.python.org/3/tutorial/errors.html), such that the program does not simply fail to check whether the file is parseable as the format specified in `format`    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec87d67-75e8-4bc7-9502-f24598959a5e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b03b52aa01bb4c3dd985217938fc69c4",
     "grade": true,
     "grade_id": "cell-7326ff597819ce15",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Data set 1\n",
    "\n",
    "Validator Used: I used the parseFile function with the format set to \"CSV.\"\n",
    "Validation Results: The result was True, which shows the dataset was correctly identified as a CSV file.\n",
    "Modification Description: To create an invalid version of this file, one could edit it by removing some of the delimiters or making the rows uneven in length. Adding some random characters that don’t fit the CSV structure would also help.\n",
    "\n",
    "Data set 2\n",
    "\n",
    "Validator Used: I used the parseFile function with the format set to \"JSON.\"\n",
    "Validation Results: The result was True, which shows the dataset was correctly identified as a JSON.\n",
    "Modification Description: To make an invalid version, one could make syntax errors like deleting commas or brackets. This would mess up the JSON structure and help to check whether the validation function catches the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5bfb28-0a4f-4fbe-a2ed-4d8e9c3d52d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eed04eccfe7b9897bc09aa0b00b66d27",
     "grade": false,
     "grade_id": "cell-e72d44bc996d8aaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [False, False, True, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import json\n",
    "#import xmltodict\n",
    "\n",
    "def parseFile(datadict, format):\n",
    "    resourceURL = datadict[\"resourceURL\"]\n",
    "    response = requests.get(resourceURL)\n",
    "    content = response.text.strip()\n",
    "\n",
    "    if format == \"JSON\":\n",
    "        if not content:\n",
    "            return False                                          # empty links\n",
    "        try:\n",
    "            json_obj = json.loads(content)                        # Try to load JSON\n",
    "            if type(json_obj) == dict or type(json_obj) == list:  # Check if it's a valid JSON object (dict or list)\n",
    "                return True\n",
    "        except Exception:\n",
    "            return False                                          # JSON parsing failed\n",
    "\n",
    "    elif format == \"XML\":\n",
    "        if not content:\n",
    "            return False \n",
    "        try:\n",
    "            xmltodict.parse(content)                              # Try to parse XML\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False                                          # XML parsing failed\n",
    "\n",
    "    elif format == \"CSV\":\n",
    "        if not content or content.startswith('{') or content.startswith('['):\n",
    "            return False                                          # Skip CSV check if content looks like JSON\n",
    "\n",
    "        delimiters = [',', ';', '\\t']\n",
    "        for delimiter in delimiters:\n",
    "            rows = content.splitlines()\n",
    "            reader = csv.reader(rows, delimiter=delimiter)\n",
    "            try:\n",
    "                row_length = []\n",
    "                for row in reader:\n",
    "                    if row:                                       # Only counts non-empty rows\n",
    "                        row_length.append(len(row))\n",
    "                                                                  # Check if all rows have the same length and are non-trivial\n",
    "                if row_length and len(set(row_length)) == 1 and row_length[0] > 1:\n",
    "                    return True\n",
    "            except Exception:\n",
    "                continue                                          # If there's an error, try the next delimiter\n",
    "        return False                                              # No valid CSV found\n",
    "\n",
    "    return False                                                  # If format is none of the above\n",
    "\n",
    "\n",
    "results = [\n",
    "    parseFile(dataset1, \"XML\"),\n",
    "    parseFile(dataset1, \"JSON\"),\n",
    "    parseFile(dataset1, \"CSV\"),\n",
    "    parseFile(dataset2, \"XML\"),\n",
    "    parseFile(dataset2, \"JSON\"),\n",
    "    parseFile(dataset2, \"CSV\")\n",
    "]\n",
    "print(\"Results:\", results)\n",
    "assert_equal(results.count(True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce5b307-c87b-4906-afc6-9c1febd645e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dba04d64b7a6dd6cedc9434b6ec78d7",
     "grade": true,
     "grade_id": "cell-44a0730c406d4f1f",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "assert_equal([parseFile(dataset1, \"XML\"),\n",
    "    parseFile(dataset1, \"JSON\"),\n",
    "    parseFile(dataset1, \"CSV\"),\n",
    "    parseFile(dataset2, \"XML\"),\n",
    "    parseFile(dataset2, \"JSON\"),\n",
    "    parseFile(dataset2, \"CSV\")].count(True), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14967cf4-e8da-4e9a-90a9-752f1f441915",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d88fca3139f38bef6d9af8192a0110a3",
     "grade": false,
     "grade_id": "cell-c0772a5952f0b1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## Step 3 - Content analysis (5 points)\n",
    "\n",
    "Similar to the Python function `parseFile(datadict,format)` above, now create a new Python function `describeFile(datadict)` that analyses the given file according to the respective format detected in Step 1 and returns a dictionary containing the following information:\n",
    "\n",
    "* for CSV files: number of columns, number of rows, column number (from 0 to n) of the column which contains the longest text. You do not have to try to transform any string to integer or float, simply take the values as is from the csv file. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfColumns:\"  ...,\n",
    "       \"numberOfRows\":  ... ,\n",
    "       \"longestColumn\" : ... }\n",
    "    ```\n",
    "\n",
    "* for JSON files: number of distinct attribute names, nesting depth, length of the longest list appearing in an attribute value. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"longestListLength\" : ... }\n",
    "     ```\n",
    "\n",
    "  Here the `longestListLength` should be set to 0 if no list appears. [Nesting depth](https://www.tutorialspoint.com/find-depth-of-a-dictionary-in-python) is defined as follows: \n",
    "   * a flat list of atomic values has depth 0, a flat JSON object with only atomic attribute values has depth 1. \n",
    "   * a JSON attribute with another object as value (or another object as member of a list value!) increases the depth by 1\n",
    "   * and so on.\n",
    "\n",
    "\n",
    "* for XML files: number of different element and attribute a names (i.e. the sum of both), nesting depth, maximum numeric value in the dataset. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfElementsAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"maxNumericValue\" : ... }\n",
    "     ```\n",
    "\n",
    "  Here the `maxNumericValue` should be set to 0 if there are no numberic values present. Nesting depth is defined as the nesting depth of elements.\n",
    "  \n",
    "For files that cannot be parsed with respective given format, the function should simply return an empty dictionary (`{}`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4494b82-73ef-410f-8646-ce960e85fae7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e05f4df55ec10447c9c1c3dbc5e19dc",
     "grade": false,
     "grade_id": "cell-223d8521820ec726",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import urllib.request\n",
    "\n",
    "def describeFile(datadict):\n",
    "   \n",
    "    resourceURL = datadict[\"resourceURL\"]\n",
    "    detectedFormat = datadict[\"detectedFormat\"]\n",
    "    # Check file type \n",
    "    if detectedFormat == \"CSV\":\n",
    "        return describeCSV(resourceURL)\n",
    "    elif detectedFormat == \"JSON\":\n",
    "        return describeJSON(resourceURL)\n",
    "    elif detectedFormat == \"XML\":\n",
    "        return describeXML(resourceURL)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def describeCSV(resourceURL):\n",
    "    \n",
    "    with urllib.request.urlopen(resourceURL) as f:\n",
    "        dialect = csv.Sniffer().sniff(f.read(5000).decode(\"utf-8\"))\n",
    "        delimiter = dialect.delimiter\n",
    "\n",
    "    \n",
    "    with urllib.request.urlopen(resourceURL) as f:\n",
    "        csv_reader = csv.reader(codecs.iterdecode(f, \"utf-8\"), delimiter=delimiter)\n",
    "        data = list(csv_reader)\n",
    "    # Calculate Number of rows and columns\n",
    "    numberOfColumns = len(data[0])\n",
    "    numberOfRows = len(data)\n",
    "    # Find column with the longest text\n",
    "    longestColumn = 0\n",
    "    Length = 0\n",
    "    for col in range(numberOfColumns):\n",
    "        for i in data:\n",
    "            if len(i[col]) > Length:\n",
    "                Length = len(i[col])\n",
    "                longestColumn = col\n",
    "    # Return the results as dictionary\n",
    "    return {\n",
    "        \"numberOfColumns\": numberOfColumns,\n",
    "        \"numberOfRows\": numberOfRows,\n",
    "        \"longestColumn\": longestColumn\n",
    "    }\n",
    "\n",
    "def describeJSON(resourceURL):\n",
    "    # Open URL and read JSON content\n",
    "    resp = urllib.request.urlopen(resourceURL)\n",
    "    data = json.loads(resp.read())\n",
    "    \n",
    "    # Find depth with recursion\n",
    "    def findNestingDepth(datJ):\n",
    "        if isinstance(datJ, dict):\n",
    "            return 1 + (max([findNestingDepth(x) for x in datJ.values()]) if datJ else 0)\n",
    "        if isinstance(datJ, list):\n",
    "            return 1 + (max([findNestingDepth(i) for i in datJ]) if datJ else 0)\n",
    "        return 0\n",
    "    \n",
    "    # Find longest list also checking if the dictonairies contain lists \n",
    "    def findLongestList(datJ):\n",
    "        if isinstance(datJ, list):\n",
    "            return max(len(datJ), max([findLongestList(i) for i in datJ] if datJ else [0]))\n",
    "        if isinstance(datJ, dict):\n",
    "            return max([findLongestList(x) for x in datJ.values()] if datJ else [0])\n",
    "        return 0\n",
    "\n",
    "    numberOfAttributes = len(data)\n",
    "    nestingDepth = findNestingDepth(data)\n",
    "    longestListLength = findLongestList(data)\n",
    "\n",
    "    return {\n",
    "        \"numberOfAttributes\": numberOfAttributes,\n",
    "        \"nestingDepth\": nestingDepth,\n",
    "        \"longestListLength\": longestListLength\n",
    "    }\n",
    "\n",
    "def describeXML(resourceURL):\n",
    "    resp = urllib.request.urlopen(resourceURL)\n",
    "    data = xmltodict.parse(resp.read())\n",
    "\n",
    "    # Find depth with recursion\n",
    "    def findNestingDepth(datX):\n",
    "        if isinstance(datX, dict):\n",
    "            return 1 + max([findNestingDepth(x) for x in datX.values()] if datX else 0)\n",
    "        if isinstance(datX, list):\n",
    "            return 1 + max([findNestingDepth(i) for i in datX] if datX else 0)\n",
    "        return 0\n",
    "    # Function to find the maximum numeric Value\n",
    "    def findMaxValue(datX):\n",
    "        maxValue = 0\n",
    "        if isinstance(datX, dict):\n",
    "            for x in datX.values():\n",
    "                maxValue = max(max_value, findMaxValue(x))\n",
    "        elif isinstance(datX, list):\n",
    "            for i in datX:\n",
    "                maxValue = max(max_value, findMaxValue(i))\n",
    "        else:\n",
    "            if isinstance(datX, (int, float)):\n",
    "                maxValue = max(max_value, datX)\n",
    "        return maxValue\n",
    "    \n",
    "    numberOfElementsAttributes = len(data)\n",
    "    nestingDepth = findNestingDepth(data)\n",
    "    maxNumericValue = findMaxValue(data)\n",
    "    \n",
    "    return {\n",
    "        \"numberOfElementsAttributes\": numberOfElementsAttributes,\n",
    "        \"nestingDepth\": nestingDepth,\n",
    "        \"maxNumericValue\": maxNumericValue\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e58d31-e57e-4ac6-84d3-48809e6b0d04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9214e0e6bbd5999d40e10489b0be7ec5",
     "grade": true,
     "grade_id": "cell-eba7f348525a45dd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "assert_equal(len(describeFile(dataset1)), 3)\n",
    "assert_equal(len(describeFile(dataset2)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bce1c-e495-4733-baa8-ddc2962f077f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df18cdf1882599d295da8465485a5b1c",
     "grade": true,
     "grade_id": "cell-4709b3248c430b6a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Dataset 1:\n",
    "The dataset contains of 10 Columns and 6670 Rows. The 0 Column contains the longest value.\n",
    "\n",
    "Dataset 2:\n",
    "The second dataset contains of 11 Attributes. The deepest level of nested elements is 5 levels deep and the longest list contains 11 items."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
